{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''解压缩数据集（不用重复操作，解压后的数据将存放于home目录下）'''\n",
    "# 解压Gray_Label.zip\n",
    "!unzip -oq /home/aistudio/data/data92773/Gray_Label.zip\n",
    "# 解压Road02.zip\n",
    "!unzip -oq /home/aistudio/data/data92773/Road02.zip\n",
    "# 解压Road03.zip\n",
    "!unzip -oq /home/aistudio/data/data92773/Road03.zip\n",
    "# 解压Road04.zip\n",
    "!unzip -oq /home/aistudio/data/data92773/Road04.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting ipywidgets\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/11/53/084940a83a8158364e630a664a30b03068c25ab75243224d6b488800d43a/ipywidgets-7.6.3-py2.py3-none-any.whl (121kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 17.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Collecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" (from ipywidgets)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/18/b5/3473d275e3b2359efdf5768e9df95537308b93a31ad94fa92814ac565826/jupyterlab_widgets-1.0.0-py3-none-any.whl (243kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 22.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (4.4.0)\n",
      "Collecting widgetsnbextension~=3.5.0 (from ipywidgets)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/6c/7b/7ac231c20d2d33c445eaacf8a433f4e22c60677eb9776c7c5262d7ddee2d/widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 20.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (7.0.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (3.1.1)\n",
      "Requirement already satisfied: jupyter_core in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.7.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (41.4.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: pygments in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.4.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.7.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.15.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.23)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (18.0.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: prometheus_client in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from prompt_toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pexpect->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (7.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Installing collected packages: jupyterlab-widgets, widgetsnbextension, ipywidgets\n",
      "Successfully installed ipywidgets-7.6.3 jupyterlab-widgets-1.0.0 widgetsnbextension-3.5.1\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 17.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.9.0)\n",
      "Collecting Shapely (from imgaug)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/98/f8/db4d3426a1aba9d5dfcc83ed5a3e2935d2b1deb73d350642931791a61c37/Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 13.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (3.3.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (7.2.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (4.1.1.26)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.5.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.19.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (0.16.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.8.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.0)\n",
      "Installing collected packages: Shapely, imgaug\n",
      "Successfully installed Shapely-1.7.1 imgaug-0.4.0\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting lmdb\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/2e/dd/ada2fd91cd7832979069c556607903f274470c3d3d2274e0a848908272e8/lmdb-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (299kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 19.0MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lmdb\n",
      "Successfully installed lmdb-1.2.1\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖包\r\n",
    "!pip install ipywidgets\r\n",
    "!pip install imgaug\r\n",
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "制作标签文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import random\r\n",
    "\r\n",
    "image_list = []\r\n",
    "label_list = []\r\n",
    "\r\n",
    "image_dirs = ['./Road%02d' % i for i in range(2, 5)]\r\n",
    "label_dir = './Gray_Label/'\r\n",
    "\r\n",
    "for image_dir in image_dirs:\r\n",
    "    road_idx = int(image_dir[-1])\r\n",
    "    image_root = os.path.join(image_dir, 'ColorImage_road%02d/ColorImage' % road_idx)\r\n",
    "    label_root = os.path.join(label_dir, 'Label_road%02d/Label' % road_idx)\r\n",
    "    # Record\r\n",
    "    for record_folder in sorted(os.listdir(image_root)):  # os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表\r\n",
    "        record_path = os.path.join(image_root, record_folder)\r\n",
    "        label_record_path = os.path.join(label_root, record_folder)\r\n",
    "        assert os.path.exists(label_record_path)\r\n",
    "        # Camera\r\n",
    "        for camera_folder in sorted(os.listdir(record_path)):\r\n",
    "            camera_path = os.path.join(record_path, camera_folder)\r\n",
    "            label_camera_path = os.path.join(label_record_path, camera_folder)\r\n",
    "            assert os.path.exists(label_camera_path)\r\n",
    "            # Image\r\n",
    "            for image_fn in sorted(os.listdir(camera_path)):\r\n",
    "                image_path = os.path.join(camera_path, image_fn)\r\n",
    "                label_path = os.path.join(label_camera_path, image_fn[:-4] + '_bin.png')  # image_fn[:-4]通过切片操作去掉文件扩展名\r\n",
    "                assert os.path.exists(label_path)\r\n",
    "                image_list.append(image_path)\r\n",
    "                label_list.append(label_path)\r\n",
    "\r\n",
    "assert len(image_list) == len(label_list), \\\r\n",
    "       \"The length of image dataset is {}, and label is {}\".format(len(image_list), len(label_list))\r\n",
    "total_length = len(image_list)\r\n",
    "eighth_part = int(total_length*0.8)\r\n",
    "\r\n",
    "image_label_list = list(zip(image_list, label_list))\r\n",
    "random.shuffle(image_label_list)\r\n",
    "\r\n",
    "train_list = image_label_list[:eighth_part]\r\n",
    "val_list = image_label_list[eighth_part:]\r\n",
    "\r\n",
    "def write_csv(data_list, csv_fn):\r\n",
    "    with open(csv_fn, 'w') as f:\r\n",
    "        for image_path, label_path in data_list:\r\n",
    "            f.write('%s, %s\\n' % (image_path, label_path))\r\n",
    "\r\n",
    "out_dir = 'data_list'\r\n",
    "if not os.path.exists(out_dir):\r\n",
    "    os.makedirs(out_dir)\r\n",
    "write_csv(train_list, os.path.join(out_dir, 'train.csv'))\r\n",
    "write_csv(val_list, os.path.join(out_dir, 'val.csv'))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "制作LMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████▎     | 36775/43828 [00:18<00:03, 2066.86it/s]"
     ]
    }
   ],
   "source": [
    "! python make_lmdb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "\r\n",
    "class Block(nn.Module):\r\n",
    "    def __init__(self, in_ch,out_ch, kernel_size=3, padding=1, stride=1):\r\n",
    "        super(Block, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride)\r\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\r\n",
    "        self.relu1 = nn.ReLU(inplace=True)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class ResBlock(nn.Module):\r\n",
    "    def __init__(self, in_ch,out_ch, kernel_size=3, padding=1, stride=1):\r\n",
    "        super(ResBlock, self).__init__()\r\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\r\n",
    "        self.relu1 = nn.ReLU(inplace=True)\r\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.conv1(self.relu1(self.bn1(x)))\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class Bottleneck(nn.Module):\r\n",
    "    expansion = 4\r\n",
    "\r\n",
    "    def __init__(self, in_chans, out_chans):\r\n",
    "        super(Bottleneck, self).__init__()\r\n",
    "        assert out_chans % 4 == 0\r\n",
    "        self.block1 = ResBlock(in_chans, int(out_chans / 4), kernel_size=1, padding=0)\r\n",
    "        self.block2 = ResBlock(int(out_chans / 4), int(out_chans / 4), kernel_size=3, padding=1)\r\n",
    "        self.block3 = ResBlock(int(out_chans / 4), out_chans, kernel_size=1, padding=0)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        identity = x\r\n",
    "        out = self.block1(x)\r\n",
    "        out = self.block2(out)\r\n",
    "        out = self.block3(out)\r\n",
    "        out += identity\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class DownBottleneck(nn.Module):\r\n",
    "    expansion = 4\r\n",
    "\r\n",
    "    def __init__(self, in_chans, out_chans, stride=2):\r\n",
    "        super(DownBottleneck, self).__init__()\r\n",
    "        assert out_chans % 4 == 0\r\n",
    "        self.block1 = ResBlock(in_chans, int(out_chans / 4), kernel_size=1, padding=0, stride=stride)\r\n",
    "        self.conv1 = nn.Conv2d(in_chans, out_chans, kernel_size=1, padding=0, stride=stride)\r\n",
    "        self.block2 = ResBlock(int(out_chans / 4), int(out_chans / 4), kernel_size=3, padding=1)\r\n",
    "        self.block3 = ResBlock(int(out_chans / 4), out_chans, kernel_size=1, padding=0)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        identity = self.conv1(x)\r\n",
    "        out = self.block1(x)\r\n",
    "        out = self.block2(out)\r\n",
    "        out = self.block3(out)\r\n",
    "        out += identity\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "def make_layers(in_channels, layer_list, name=\"vgg\"):\r\n",
    "    layers = []\r\n",
    "    if name == \"vgg\":\r\n",
    "        for v in layer_list:\r\n",
    "            layers += [Block(in_channels, v)]\r\n",
    "            in_channels = v\r\n",
    "    elif name == \"resnet\":\r\n",
    "        layers += [DownBottleneck(in_channels, layer_list[0])]\r\n",
    "        in_channels = layer_list[0]\r\n",
    "        for v in layer_list[1:]:\r\n",
    "            layers += [Bottleneck(in_channels, v)]\r\n",
    "            in_channels = v\r\n",
    "    return nn.Sequential(*layers)\r\n",
    "\r\n",
    "\r\n",
    "class Layer(nn.Module):\r\n",
    "    def __init__(self, in_channels, layer_list, net_name):\r\n",
    "        super(Layer, self).__init__()\r\n",
    "        self.layer = make_layers(in_channels, layer_list, name=net_name)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer(x)\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class ASPP(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, in_chans, out_chans, rate=1):\r\n",
    "        super(ASPP, self).__init__()\r\n",
    "        self.branch1 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_chans, out_chans, 1, 1, padding=0, dilation=rate, bias=True),\r\n",
    "            nn.BatchNorm2d(out_chans),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        self.branch2 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=6 * rate, dilation=6 * rate, bias=True),\r\n",
    "            nn.BatchNorm2d(out_chans),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        self.branch3 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=12 * rate, dilation=12 * rate, bias=True),\r\n",
    "            nn.BatchNorm2d(out_chans),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        self.branch4 = nn.Sequential(\r\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=18 * rate, dilation=18 * rate, bias=True),\r\n",
    "            nn.BatchNorm2d(out_chans),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        self.branch5_avg = nn.AdaptiveAvgPool2d(1)\r\n",
    "        self.branch5_conv = nn.Conv2d(in_chans, out_chans, 1, 1, 0, bias=True)\r\n",
    "        self.branch5_bn = nn.BatchNorm2d(out_chans)\r\n",
    "        self.branch5_relu = nn.ReLU(inplace=True)\r\n",
    "        self.conv_cat = nn.Sequential(\r\n",
    "            nn.Conv2d(out_chans * 5, out_chans, 1, 1, padding=0, bias=True),\r\n",
    "            nn.BatchNorm2d(out_chans),\r\n",
    "            nn.ReLU(inplace=True))\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        b, c, h, w = x.size()\r\n",
    "        conv1x1 = self.branch1(x)\r\n",
    "        conv3x3_1 = self.branch2(x)\r\n",
    "        conv3x3_2 = self.branch3(x)\r\n",
    "        conv3x3_3 = self.branch4(x)\r\n",
    "        global_feature = self.branch5_avg(x)\r\n",
    "        global_feature = self.branch5_relu(self.branch5_bn(self.branch5_conv(global_feature)))\r\n",
    "        global_feature = F.interpolate(global_feature, (h, w), None, 'bilinear', True)\r\n",
    "\r\n",
    "        feature_cat = torch.cat([conv1x1, conv3x3_1, conv3x3_2, conv3x3_3, global_feature], dim=1)\r\n",
    "        result = self.conv_cat(feature_cat)\r\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.utils.model_zoo as model_zoo\r\n",
    "\r\n",
    "bn_mom = 0.0003\r\n",
    "model_urls = {\r\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\r\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\r\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\r\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "def conv3x3(in_planes, out_planes, stride=1, atrous=1):\r\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\r\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
    "                     padding=1 * atrous, dilation=atrous, bias=False)\r\n",
    "\r\n",
    "\r\n",
    "class BasicBlock(nn.Module):\r\n",
    "    expansion = 1\r\n",
    "\r\n",
    "    def __init__(self, in_chans, out_chans, stride=1, atrous=1, downsample=None):\r\n",
    "        super(BasicBlock, self).__init__()\r\n",
    "        self.conv1 = conv3x3(in_chans, out_chans, stride, atrous)\r\n",
    "        self.bn1 = nn.BatchNorm2d(out_chans)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.conv2 = conv3x3(out_chans, out_chans)\r\n",
    "        self.bn2 = nn.BatchNorm2d(out_chans)\r\n",
    "        self.downsample = downsample\r\n",
    "        self.stride = stride\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        residual = x\r\n",
    "\r\n",
    "        out = self.conv1(x)\r\n",
    "        out = self.bn1(out)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        out = self.conv2(out)\r\n",
    "        out = self.bn2(out)\r\n",
    "\r\n",
    "        if self.downsample is not None:\r\n",
    "            residual = self.downsample(x)\r\n",
    "\r\n",
    "        out += residual\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class Bottleneck(nn.Module):\r\n",
    "    expansion = 4\r\n",
    "\r\n",
    "    def __init__(self, in_chans, out_chans, stride=1, atrous=1, downsample=None):\r\n",
    "        super(Bottleneck, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(in_chans, out_chans, kernel_size=1, bias=False)\r\n",
    "        self.bn1 = nn.BatchNorm2d(out_chans)\r\n",
    "        self.conv2 = nn.Conv2d(out_chans, out_chans, kernel_size=3, stride=stride,\r\n",
    "                               padding=1 * atrous, dilation=atrous, bias=False)\r\n",
    "        self.bn2 = nn.BatchNorm2d(out_chans)\r\n",
    "        self.conv3 = nn.Conv2d(out_chans, out_chans * self.expansion, kernel_size=1, bias=False)\r\n",
    "        self.bn3 = nn.BatchNorm2d(out_chans * self.expansion)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.downsample = downsample\r\n",
    "        self.stride = stride\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        residual = x\r\n",
    "\r\n",
    "        out = self.conv1(x)\r\n",
    "        out = self.bn1(out)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        out = self.conv2(out)\r\n",
    "        out = self.bn2(out)\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        out = self.conv3(out)\r\n",
    "        out = self.bn3(out)\r\n",
    "\r\n",
    "        if self.downsample is not None:\r\n",
    "            residual = self.downsample(x)\r\n",
    "\r\n",
    "        out += residual\r\n",
    "        out = self.relu(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "\r\n",
    "class ResNet_Atrous(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, block, layers, atrous=None, os=16):\r\n",
    "        super(ResNet_Atrous, self).__init__()\r\n",
    "        stride_list = None\r\n",
    "        if os == 8:\r\n",
    "            stride_list = [2, 1, 1]\r\n",
    "        elif os == 16:\r\n",
    "            stride_list = [2, 2, 1]\r\n",
    "        else:\r\n",
    "            raise ValueError('resnet_atrous.py: output stride=%d is not supported.' % os)\r\n",
    "\r\n",
    "        self.inplanes = 64\r\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\r\n",
    "                               bias=False)\r\n",
    "\r\n",
    "        self.bn1 = nn.BatchNorm2d(64)\r\n",
    "        self.relu = nn.ReLU(inplace=True)\r\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
    "        self.layer1 = self._make_layer(block, 64, 64, layers[0])\r\n",
    "        self.layer2 = self._make_layer(block, 256, 128, layers[1], stride=stride_list[0])\r\n",
    "        self.layer3 = self._make_layer(block, 512, 256, layers[2], stride=stride_list[1], atrous=16 // os)\r\n",
    "        self.layer4 = self._make_layer(block, 1024, 512, layers[3], stride=stride_list[2],\r\n",
    "                                       atrous=[item * 16 // os for item in atrous])\r\n",
    "        self.layer5 = self._make_layer(block, 2048, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\r\n",
    "        self.layer6 = self._make_layer(block, 2048, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\r\n",
    "        self.layers = []\r\n",
    "\r\n",
    "        for m in self.modules():\r\n",
    "            if isinstance(m, nn.Conv2d):\r\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
    "            elif isinstance(m, nn.BatchNorm2d):\r\n",
    "                nn.init.constant_(m.weight, 1)\r\n",
    "                nn.init.constant_(m.bias, 0)\r\n",
    "\r\n",
    "    def _make_layer(self, block, in_chans, out_chans, blocks, stride=1, atrous=None):\r\n",
    "        downsample = None\r\n",
    "        if atrous == None:\r\n",
    "            atrous = [1] * blocks\r\n",
    "        elif isinstance(atrous, int):\r\n",
    "            atrous_list = [atrous] * blocks\r\n",
    "            atrous = atrous_list\r\n",
    "        if stride != 1 or in_chans != out_chans * block.expansion:\r\n",
    "            downsample = nn.Sequential(\r\n",
    "                nn.Conv2d(in_chans, out_chans * block.expansion,\r\n",
    "                          kernel_size=1, stride=stride, bias=False),\r\n",
    "                nn.BatchNorm2d(out_chans * block.expansion),\r\n",
    "            )\r\n",
    "\r\n",
    "        layers = []\r\n",
    "        layers.append(block(in_chans, out_chans, stride=stride, atrous=atrous[0], downsample=downsample))\r\n",
    "        in_chans = out_chans*4\r\n",
    "        for i in range(1, blocks):\r\n",
    "            layers.append(block(in_chans, out_chans, stride=1, atrous=atrous[i]))\r\n",
    "\r\n",
    "        return nn.Sequential(*layers)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        layers_list = []\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = self.bn1(x)\r\n",
    "        x = self.relu(x)\r\n",
    "        x = self.maxpool(x)\r\n",
    "        x = self.layer1(x)\r\n",
    "        layers_list.append(x)\r\n",
    "        x = self.layer2(x)\r\n",
    "        layers_list.append(x)\r\n",
    "        x = self.layer3(x)\r\n",
    "        layers_list.append(x)\r\n",
    "        x = self.layer4(x)\r\n",
    "        x = self.layer5(x)\r\n",
    "        x = self.layer6(x)\r\n",
    "        layers_list.append(x)\r\n",
    "\r\n",
    "        return layers_list\r\n",
    "\r\n",
    "\r\n",
    "def resnet50_atrous(pretrained=True, os=16, **kwargs):\r\n",
    "    \"\"\"Constructs a atrous ResNet-50 model.\"\"\"\r\n",
    "    model = ResNet_Atrous(Bottleneck, [3, 4, 6, 3], atrous=[1, 2, 1], os=os, **kwargs)\r\n",
    "    if pretrained:\r\n",
    "        old_dict = model_zoo.load_url(model_urls['resnet50'])\r\n",
    "        model_dict = model.state_dict()\r\n",
    "        old_dict = {k: v for k, v in old_dict.items() if (k in model_dict)}\r\n",
    "        model_dict.update(old_dict)\r\n",
    "        model.load_state_dict(model_dict)\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "def resnet101_atrous(pretrained=True, os=16, **kwargs):\r\n",
    "    \"\"\"Constructs a atrous ResNet-101 model.\"\"\"\r\n",
    "    model = ResNet_Atrous(Bottleneck, [3, 4, 23, 3], atrous=[1, 2, 1], os=os, **kwargs)\r\n",
    "    if pretrained:\r\n",
    "        old_dict = model_zoo.load_url(model_urls['resnet101'])\r\n",
    "        model_dict = model.state_dict()\r\n",
    "        old_dict = {k: v for k, v in old_dict.items() if (k in model_dict)}\r\n",
    "        model_dict.update(old_dict)\r\n",
    "        model.load_state_dict(model_dict)\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class DeeplabV3Plus(nn.Module):\r\n",
    "    def __init__(self, cfg):\r\n",
    "        super(DeeplabV3Plus, self).__init__()\r\n",
    "        self.backbone = resnet50_atrous(pretrained=True, os=cfg.OUTPUT_STRIDE)\r\n",
    "        input_channel = 2048\r\n",
    "        self.aspp = ASPP(in_chans=input_channel, out_chans=cfg.ASPP_OUTDIM, rate=16//cfg.OUTPUT_STRIDE)\r\n",
    "        self.dropout1 = nn.Dropout(0.5)\r\n",
    "        self.upsample4 = nn.UpsamplingBilinear2d(scale_factor=4)\r\n",
    "        self.upsample_sub = nn.UpsamplingBilinear2d(scale_factor=cfg.OUTPUT_STRIDE//4)\r\n",
    "\r\n",
    "        indim = 256\r\n",
    "        self.shortcut_conv = nn.Sequential(\r\n",
    "                nn.Conv2d(indim, cfg.SHORTCUT_DIM, cfg.SHORTCUT_KERNEL, 1, padding=cfg.SHORTCUT_KERNEL//2,bias=False),\r\n",
    "                nn.BatchNorm2d(cfg.SHORTCUT_DIM),\r\n",
    "                nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        self.cat_conv = nn.Sequential(\r\n",
    "                nn.Conv2d(cfg.ASPP_OUTDIM+cfg.SHORTCUT_DIM, cfg.ASPP_OUTDIM, 3, 1, padding=1,bias=False),\r\n",
    "                nn.BatchNorm2d(cfg.ASPP_OUTDIM),\r\n",
    "                nn.ReLU(inplace=True),\r\n",
    "                nn.Dropout(0.5),\r\n",
    "                nn.Conv2d(cfg.ASPP_OUTDIM, cfg.ASPP_OUTDIM, 3, 1, padding=1, bias=False),\r\n",
    "                nn.BatchNorm2d(cfg.ASPP_OUTDIM),\r\n",
    "                nn.ReLU(inplace=True),\r\n",
    "                nn.Dropout(0.1),\r\n",
    "        )\r\n",
    "        self.cls_conv = nn.Conv2d(cfg.ASPP_OUTDIM, cfg.NUM_CLASSES, 1, 1, padding=0)\r\n",
    "        for m in self.modules():\r\n",
    "            if isinstance(m, nn.Conv2d):\r\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
    "            elif isinstance(m, nn.BatchNorm2d):\r\n",
    "                nn.init.constant_(m.weight, 1)\r\n",
    "                nn.init.constant_(m.bias, 0)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        layers = self.backbone(x)\r\n",
    "        feature_aspp = self.aspp(layers[-1])\r\n",
    "        feature_aspp = self.dropout1(feature_aspp)\r\n",
    "        feature_aspp = self.upsample_sub(feature_aspp)\r\n",
    "\r\n",
    "        feature_shallow = self.shortcut_conv(layers[0])\r\n",
    "        feature_cat = torch.cat([feature_aspp, feature_shallow],1)\r\n",
    "        result = self.cat_conv(feature_cat)\r\n",
    "        result = self.cls_conv(result)\r\n",
    "        result = self.upsample4(result)\r\n",
    "        return result\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class UNetConvBlock(nn.Module):\r\n",
    "    def __init__(self, in_chans, out_chans, padding, batch_norm):\r\n",
    "        super(UNetConvBlock, self).__init__()\r\n",
    "        block = []\r\n",
    "\r\n",
    "        block.append(nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=int(padding)))\r\n",
    "        block.append(nn.ReLU())\r\n",
    "        if batch_norm:\r\n",
    "            block.append(nn.BatchNorm2d(out_chans))\r\n",
    "\r\n",
    "        block.append(nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=int(padding)))\r\n",
    "        block.append(nn.ReLU())\r\n",
    "        if batch_norm:\r\n",
    "            block.append(nn.BatchNorm2d(out_chans))\r\n",
    "\r\n",
    "        self.block = nn.Sequential(*block)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.block(x)\r\n",
    "        return out\r\n",
    "\r\n",
    "class UNetUpBlock(nn.Module):\r\n",
    "    def __init__(self, in_chans, out_chans, up_mode, padding):\r\n",
    "        super(UNetUpBlock, self).__init__()\r\n",
    "        if up_mode == 'upconv':\r\n",
    "            self.up = nn.ConvTranspose2d(in_chans, out_chans, kernel_size=2, stride=2)\r\n",
    "        elif up_mode == 'upsample':\r\n",
    "            self.up = nn.Sequential(\r\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\r\n",
    "                nn.Conv2d(in_chans, out_chans, kernel_size=1),\r\n",
    "            )\r\n",
    "        self.conv_block = UNetConvBlock(in_chans, out_chans, padding, True)\r\n",
    "\r\n",
    "    def center_crop(self, layer, target_size):\r\n",
    "        _, _, layer_height, layer_width = layer.size()\r\n",
    "        diff_y = (layer_height - target_size[0]) // 2\r\n",
    "        diff_x = (layer_width - target_size[1]) // 2\r\n",
    "        return layer[\r\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\r\n",
    "        ]\r\n",
    "\r\n",
    "    def forward(self, x, bridge):\r\n",
    "        up = self.up(x)\r\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\r\n",
    "        out = torch.cat([crop1, up], dim=1)\r\n",
    "        out = self.conv_block(out)\r\n",
    "\r\n",
    "        return out\r\n",
    "\r\n",
    "class ResNetUNet(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        config\r\n",
    "    ):\r\n",
    "        super(ResNetUNet, self).__init__()\r\n",
    "        self.n_classes = config.NUM_CLASSES\r\n",
    "        self.padding = 1\r\n",
    "        self.up_mode = 'upconv'\r\n",
    "        assert self.up_mode in ('upconv', 'upsample')\r\n",
    "        self.encode = ResNet101v2()\r\n",
    "        prev_channels = 2048\r\n",
    "        self.up_path = nn.ModuleList()\r\n",
    "        for i in range(3):\r\n",
    "            self.up_path.append(\r\n",
    "                UNetUpBlock(prev_channels, prev_channels // 2, self.up_mode, self.padding)\r\n",
    "            )\r\n",
    "            prev_channels //= 2\r\n",
    "\r\n",
    "        self.cls_conv_block1 = Block(prev_channels, 32)\r\n",
    "        self.cls_conv_block2 = Block(32, 16)\r\n",
    "        self.last = nn.Conv2d(16, self.n_classes, kernel_size=1)\r\n",
    "        \r\n",
    "        for m in self.modules():\r\n",
    "            if isinstance(m, nn.Conv2d):\r\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
    "            elif isinstance(m, nn.BatchNorm2d):\r\n",
    "                nn.init.constant_(m.weight, 1)\r\n",
    "                nn.init.constant_(m.bias, 0)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        input_size = x.size()[2:]\r\n",
    "        blocks = self.encode(x)\r\n",
    "        x = blocks[-1]\r\n",
    "        for i, up in enumerate(self.up_path):\r\n",
    "            x = up(x, blocks[-i - 2])\r\n",
    "        x = nn.Upsample(size=input_size, mode='bilinear', align_corners=True)(x)\r\n",
    "        x = self.cls_conv_block1(x)\r\n",
    "        x = self.cls_conv_block2(x)\r\n",
    "        x = self.last(x)\r\n",
    "        return x\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "class ResNet101v2(nn.Module):\r\n",
    "    '''\r\n",
    "    ResNet101 model \r\n",
    "    '''\r\n",
    "    def __init__(self):\r\n",
    "        super(ResNet101v2, self).__init__()\r\n",
    "        self.conv1 = Block(3, 64, 7, 3, 2)\r\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\r\n",
    "        self.conv2_1 =DownBottleneck(64, 256, stride=1)\r\n",
    "        self.conv2_2 =Bottleneck(256, 256)\r\n",
    "        self.conv2_3 =Bottleneck(256, 256)\r\n",
    "        self.layer3 = Layer(256, [512]*2, \"resnet\")\r\n",
    "        self.layer4 = Layer(512, [1024]*23, \"resnet\")\r\n",
    "        self.layer5 = Layer(1024, [2048]*3, \"resnet\")\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        f1 = self.conv1(x)\r\n",
    "        f2 = self.conv2_3(self.conv2_2(self.conv2_1(self.pool1(f1))))\r\n",
    "        f3 = self.layer3(f2)\r\n",
    "        f4 = self.layer4(f3)\r\n",
    "        f5 = self.layer5(f4)\r\n",
    "        return [f2, f3, f4, f5]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import colorsys\r\n",
    "\r\n",
    "\r\n",
    "def encode_labels(color_mask):\r\n",
    "    encode_mask = np.zeros((color_mask.shape[0], color_mask.shape[1]))\r\n",
    "    # 0\r\n",
    "    id_train = {0:[0, 249, 255, 213, 206, 207, 211, 208,216,215,218, 219,232, 202, 231,230,228,229,233,212,223],\r\n",
    "                1:[200, 204, 209], 2: [201,203], 3:[217], 4:[210], 5:[214],\r\n",
    "                6:[220,221,222,224,225,226], 7:[205,227,250]}\r\n",
    "    for i in range(8):\r\n",
    "        for item in id_train[i]:\r\n",
    "            encode_mask[color_mask == item] = i\r\n",
    "\r\n",
    "    return encode_mask\r\n",
    "\r\n",
    "\r\n",
    "def decode_labels(labels):\r\n",
    "    deocde_mask = np.zeros((labels.shape[0], labels.shape[1]), dtype='uint8')\r\n",
    "    # 0\r\n",
    "    deocde_mask[labels == 0] = 0\r\n",
    "    # 1\r\n",
    "    deocde_mask[labels == 1] = 204\r\n",
    "    # 2\r\n",
    "    deocde_mask[labels == 2] = 203\r\n",
    "    # 3\r\n",
    "    deocde_mask[labels == 3] = 217\r\n",
    "    # 4\r\n",
    "    deocde_mask[labels == 4] = 210\r\n",
    "    # 5\r\n",
    "    deocde_mask[labels == 5] = 214\r\n",
    "    # 6\r\n",
    "    deocde_mask[labels == 6] = 224\r\n",
    "    # 7\r\n",
    "    deocde_mask[labels == 7] = 227\r\n",
    "\r\n",
    "    return deocde_mask\r\n",
    "\r\n",
    "\r\n",
    "def decode_color_labels(labels):\r\n",
    "    decode_mask = np.zeros((3, labels.shape[0], labels.shape[1]), dtype='uint8')\r\n",
    "    # 0\r\n",
    "    decode_mask[0][labels == 0] = 0\r\n",
    "    decode_mask[1][labels == 0] = 0\r\n",
    "    decode_mask[2][labels == 0] = 0\r\n",
    "    # 1\r\n",
    "    decode_mask[0][labels == 1] = 70\r\n",
    "    decode_mask[1][labels == 1] = 130\r\n",
    "    decode_mask[2][labels == 1] = 180\r\n",
    "    # 2\r\n",
    "    decode_mask[0][labels == 2] = 0\r\n",
    "    decode_mask[1][labels == 2] = 0\r\n",
    "    decode_mask[2][labels == 2] = 142\r\n",
    "    # 3\r\n",
    "    decode_mask[0][labels == 3] = 153\r\n",
    "    decode_mask[1][labels == 3] = 153\r\n",
    "    decode_mask[2][labels == 3] = 153\r\n",
    "    # 4\r\n",
    "    decode_mask[0][labels == 4] = 128\r\n",
    "    decode_mask[1][labels == 4] = 64\r\n",
    "    decode_mask[2][labels == 4] = 128\r\n",
    "    # 5\r\n",
    "    decode_mask[0][labels == 5] = 190\r\n",
    "    decode_mask[1][labels == 5] = 153\r\n",
    "    decode_mask[2][labels == 5] = 153\r\n",
    "    # 6\r\n",
    "    decode_mask[0][labels == 6] = 0\r\n",
    "    decode_mask[1][labels == 6] = 0\r\n",
    "    decode_mask[2][labels == 6] = 230\r\n",
    "    # 7\r\n",
    "    decode_mask[0][labels == 7] = 255\r\n",
    "    decode_mask[1][labels == 7] = 128\r\n",
    "    decode_mask[2][labels == 7] = 0\r\n",
    "\r\n",
    "    return decode_mask\r\n",
    "\r\n",
    "\r\n",
    "def class_colors(num_classes, bright=True):\r\n",
    "    \"\"\"\r\n",
    "    based on the class id to choose a centrial color to show them\r\n",
    "    \"\"\"\r\n",
    "    brightness = 1.0 if bright else 0.7\r\n",
    "    hsv = [(i / np.float (num_classes), 1, brightness) for i in range (num_classes)]\r\n",
    "    color_map = list (map (lambda c: colorsys.hsv_to_rgb (*c), hsv))\r\n",
    "    color_map = np.array(color_map)\r\n",
    "\r\n",
    "    return color_map\r\n",
    "\r\n",
    "\r\n",
    "def verify_labels(labels):\r\n",
    "    pixels = [0]\r\n",
    "    for x in range(labels.shape[0]):\r\n",
    "        for y in range(labels.shape[1]):\r\n",
    "            pixel = labels[x, y]\r\n",
    "            if pixel not in pixels:\r\n",
    "                pixels.append(pixel)\r\n",
    "    print('The Labels Has Value:', pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "import lmdb\r\n",
    "import random\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from imgaug import augmenters as iaa\r\n",
    "\r\n",
    "\r\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\r\n",
    "\r\n",
    "\r\n",
    "# crop the image to discard useless parts\r\n",
    "def crop_resize_data(image, label=None, image_size=(1024, 384), offset=690):\r\n",
    "    \"\"\"\r\n",
    "    Attention:\r\n",
    "    h,w,c = image.shape\r\n",
    "    cv2.resize(image,(w,h))\r\n",
    "    \"\"\"\r\n",
    "    roi_image = image[offset:, :]\r\n",
    "    if label is not None:\r\n",
    "        roi_label = label[offset:, :]\r\n",
    "        train_image = cv2.resize(roi_image, image_size, interpolation=cv2.INTER_LINEAR)\r\n",
    "        train_label = cv2.resize(roi_label, image_size, interpolation=cv2.INTER_NEAREST)\r\n",
    "        return train_image, train_label\r\n",
    "    else:\r\n",
    "        train_image = cv2.resize(roi_image, image_size, interpolation=cv2.INTER_LINEAR)\r\n",
    "        return train_image\r\n",
    "\r\n",
    "\r\n",
    "class LaneDataset(Dataset):\r\n",
    "\r\n",
    "    def __init__(self, csv_file, transform=None):\r\n",
    "        super(LaneDataset, self).__init__()\r\n",
    "        \r\n",
    "        with open(csv_file, 'r') as f:\r\n",
    "            lines = f.readlines()\r\n",
    "            self.paths = [line.strip().split(', ') for line in lines]\r\n",
    "        self.images = [path[0] for path in self.paths]\r\n",
    "        self.labels = [path[1] for path in self.paths]\r\n",
    "        self.transform = transform\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.images)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "\r\n",
    "        train_img = cv2.imread(self.images[idx])\r\n",
    "        train_mask = cv2.imread(self.labels[idx], cv2.IMREAD_GRAYSCALE)\r\n",
    "        train_img, train_mask = crop_resize_data(train_img, train_mask)\r\n",
    "        # Encode\r\n",
    "        train_mask = encode_labels(train_mask)\r\n",
    "        sample = [train_img.copy(), train_mask.copy()]\r\n",
    "        if self.transform:\r\n",
    "            sample = self.transform(sample)\r\n",
    "        return sample\r\n",
    "\r\n",
    "\r\n",
    "class LaneDatasetLMDB(Dataset):\r\n",
    "\r\n",
    "    def __init__(self, csv_file, lmdb_path, transform=None):\r\n",
    "        super(LaneDatasetLMDB, self).__init__()\r\n",
    "        \r\n",
    "        self.env = lmdb.open(lmdb_path)\r\n",
    "        self.txn = self.env.begin(write=False)\r\n",
    "        with open(csv_file, 'r') as f:\r\n",
    "            lines = f.readlines()\r\n",
    "            self.paths = [line.strip().split(', ') for line in lines]\r\n",
    "        self.images = [path[0] for path in self.paths]\r\n",
    "        self.labels = [path[1] for path in self.paths]\r\n",
    "\r\n",
    "        self.transform = transform\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.images)\r\n",
    "        \r\n",
    "    def __del__(self):\r\n",
    "        self.env.close()\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "\r\n",
    "        image_bytes = self.txn.get(self.images[idx].encode())\r\n",
    "        image_bytes = np.array(bytearray(image_bytes), dtype=np.uint8)\r\n",
    "        mask_bytes = self.txn.get(self.labels[idx].encode())\r\n",
    "        mask_bytes = np.array(bytearray(mask_bytes), dtype=np.uint8)\r\n",
    "        train_img= cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\r\n",
    "        train_mask = cv2.imdecode(mask_bytes, cv2.IMREAD_GRAYSCALE)\r\n",
    "        \r\n",
    "        train_img, train_mask = crop_resize_data(train_img, train_mask)\r\n",
    "        # Encode\r\n",
    "        train_mask = encode_labels(train_mask)\r\n",
    "        sample = [train_img.copy(), train_mask.copy()]\r\n",
    "        if self.transform:\r\n",
    "            sample = self.transform(sample)\r\n",
    "        return sample\r\n",
    "        \r\n",
    "        \r\n",
    "# pixel augmentation\r\n",
    "class ImageAug(object):\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, mask = sample\r\n",
    "        if np.random.uniform(0,1) > 0.5:\r\n",
    "            seq = iaa.Sequential([iaa.OneOf([\r\n",
    "                iaa.AdditiveGaussianNoise(scale=(0, 0.2 * 255)),\r\n",
    "                iaa.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.3)),\r\n",
    "                iaa.GaussianBlur(sigma=(0, 1.0)),\r\n",
    "                # iaa.LinearContrast((0.75,1.5))\r\n",
    "                ])])\r\n",
    "            image = seq.augment_image(image)\r\n",
    "        return image, mask\r\n",
    "\r\n",
    "\r\n",
    "# deformation augmentation\r\n",
    "class DeformAug(object):\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, mask = sample\r\n",
    "        seq = iaa.Sequential([iaa.CropAndPad(percent=(-0.05, 0.1))])\r\n",
    "        seg_to = seq.to_deterministic()\r\n",
    "        image = seg_to.augment_image(image)\r\n",
    "        mask = seg_to.augment_image(mask)\r\n",
    "        return image, mask\r\n",
    "\r\n",
    "\r\n",
    "class ScaleAug(object):\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, mask = sample\r\n",
    "        scale = random.uniform(0.7, 1.5)\r\n",
    "        h, w, _ = image.shape\r\n",
    "        aug_image = image.copy()\r\n",
    "        aug_mask = mask.copy()\r\n",
    "        aug_image = cv2.resize(aug_image, (int (scale * w), int (scale * h)))\r\n",
    "        aug_mask = cv2.resize(aug_mask, (int (scale * w), int (scale * h)))\r\n",
    "        if (scale < 1.0):\r\n",
    "            new_h, new_w, _ = aug_image.shape\r\n",
    "            pre_h_pad = int((h - new_h) / 2)\r\n",
    "            pre_w_pad = int((w - new_w) / 2)\r\n",
    "            pad_list = [[pre_h_pad, h - new_h - pre_h_pad], [pre_w_pad, w - new_w - pre_w_pad], [0, 0]]\r\n",
    "            aug_image = np.pad(aug_image, pad_list, mode=\"constant\")\r\n",
    "            aug_mask = np.pad(aug_mask, pad_list[:2], mode=\"constant\")\r\n",
    "        if (scale > 1.0):\r\n",
    "            new_h, new_w, _ = aug_image.shape\r\n",
    "            pre_h_crop = int ((new_h - h) / 2)\r\n",
    "            pre_w_crop = int ((new_w - w) / 2)\r\n",
    "            post_h_crop = h + pre_h_crop\r\n",
    "            post_w_crop = w + pre_w_crop\r\n",
    "            aug_image = aug_image[pre_h_crop:post_h_crop, pre_w_crop:post_w_crop]\r\n",
    "            aug_mask = aug_mask[pre_h_crop:post_h_crop, pre_w_crop:post_w_crop]\r\n",
    "        return aug_image, aug_mask\r\n",
    "\r\n",
    "\r\n",
    "class CutOut(object):\r\n",
    "    def __init__(self, mask_size, p):\r\n",
    "        self.mask_size = mask_size\r\n",
    "        self.p = p\r\n",
    "\r\n",
    "    def __call__(self, sample):\r\n",
    "        image, mask = sample\r\n",
    "        mask_size_half = self.mask_size // 2\r\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\r\n",
    "\r\n",
    "        h, w = image.shape[:2]\r\n",
    "        cxmin, cxmax = mask_size_half, w + offset - mask_size_half\r\n",
    "        cymin, cymax = mask_size_half, h + offset - mask_size_half\r\n",
    "        cx = np.random.randint(cxmin, cxmax)\r\n",
    "        cy = np.random.randint(cymin, cymax)\r\n",
    "        xmin, ymin = cx - mask_size_half, cy - mask_size_half\r\n",
    "        xmax, ymax = xmin + self.mask_size, ymin + self.mask_size\r\n",
    "        xmin, ymin, xmax, ymax = max(0, xmin), max(0, ymin), min(w, xmax), min(h, ymax)\r\n",
    "        if np.random.uniform(0, 1) < self.p:\r\n",
    "            image[ymin:ymax, xmin:xmax] = (0, 0, 0)\r\n",
    "        return image, mask\r\n",
    "\r\n",
    "\r\n",
    "class ToTensor(object):\r\n",
    "    def __call__(self, sample):\r\n",
    "\r\n",
    "        image, mask = sample\r\n",
    "        image = np.transpose(image,(2,0,1))\r\n",
    "        image = image.astype(np.float32)\r\n",
    "        mask = mask.astype(np.long)\r\n",
    "        return {'image': torch.from_numpy(image.copy()),\r\n",
    "                'mask': torch.from_numpy(mask.copy())}\r\n",
    "\r\n",
    "\r\n",
    "def expand_resize_data(prediction=None, submission_size=(3384, 1710), offset=690):\r\n",
    "    pred_mask = decode_labels(prediction)\r\n",
    "    expand_mask = cv2.resize(pred_mask, (submission_size[0], submission_size[1] - offset), interpolation=cv2.INTER_NEAREST)\r\n",
    "    submission_mask = np.zeros((submission_size[1], submission_size[0]), dtype='uint8')\r\n",
    "    submission_mask[offset:, :] = expand_mask\r\n",
    "    return submission_mask\r\n",
    "\r\n",
    "\r\n",
    "def expand_resize_color_data(prediction=None, submission_size=(3384, 1710), offset=690):\r\n",
    "    color_pred_mask = decode_color_labels(prediction)\r\n",
    "    color_pred_mask = np.transpose(color_pred_mask, (1, 2, 0))\r\n",
    "    color_expand_mask = cv2.resize(color_pred_mask, (submission_size[0], submission_size[1] - offset), interpolation=cv2.INTER_NEAREST)\r\n",
    "    color_submission_mask = np.zeros((submission_size[1], submission_size[0], 3), dtype='uint8')\r\n",
    "    color_submission_mask[offset:, :, :] = color_expand_mask\r\n",
    "    return color_submission_mask\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySoftmaxCrossEntropyLoss(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, nbclasses):\r\n",
    "        super(MySoftmaxCrossEntropyLoss, self).__init__()\r\n",
    "        self.nbclasses = nbclasses\r\n",
    "\r\n",
    "    def forward(self, inputs, target):\r\n",
    "        if inputs.dim() > 2:\r\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\r\n",
    "            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\r\n",
    "            inputs = inputs.contiguous().view(-1, self.nbclasses)  # N,H*W,C => N*H*W,C\r\n",
    "        target = target.view(-1)\r\n",
    "        return nn.CrossEntropyLoss(reduction=\"mean\")(inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def diceCoeff(pred, gt, smooth=1e-5, activation='sigmoid'):\r\n",
    "    \"\"\" computational formula：\r\n",
    "        dice = (2 * (pred ∩ gt)) / (pred ∪ gt)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    if activation is None or activation == \"none\":\r\n",
    "        activation_fn = lambda x: x\r\n",
    "    elif activation == \"sigmoid\":\r\n",
    "        activation_fn = nn.Sigmoid()\r\n",
    "    elif activation == \"softmax2d\":\r\n",
    "        activation_fn = nn.Softmax2d()\r\n",
    "    else:\r\n",
    "        raise NotImplementedError(\"Activation implemented for sigmoid and softmax2d\")\r\n",
    "\r\n",
    "    pred = activation_fn(pred)\r\n",
    "\r\n",
    "    N = gt.size(0)\r\n",
    "    pred_flat = pred.view(N, -1)\r\n",
    "    gt_flat = gt.view(N, -1)\r\n",
    "    intersection = (pred_flat * gt_flat).sum(1)\r\n",
    "    unionset = pred_flat.sum(1) + gt_flat.sum(1)\r\n",
    "    loss = (2 * intersection + smooth) / (unionset + smooth)\r\n",
    "\r\n",
    "    return loss.sum() / N\r\n",
    "\r\n",
    "\r\n",
    "class DiceLoss(nn.Module):\r\n",
    "    def __init__(self, nbclasses, activation='sigmoid'):\r\n",
    "        super(DiceLoss, self).__init__()\r\n",
    "        self.activation = activation\r\n",
    "        self.nbclasses = nbclasses\r\n",
    "\r\n",
    "    def forward(self, inputs, target):\r\n",
    "        class_dice = []\r\n",
    "        for i in range(1, self.nbclasses):\r\n",
    "            target = target == i\r\n",
    "            class_dice.append(diceCoeff(inputs[:, i:i + 1, :], target, activation=self.activation))\r\n",
    "        mean_dice = sum(class_dice) / len(class_dice)\r\n",
    "        return 1 - mean_dice\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_iou(pred, gt, result):\r\n",
    "    \"\"\"\r\n",
    "    pred : [N, H, W]\r\n",
    "    gt: [N, H, W]\r\n",
    "    \"\"\"\r\n",
    "    pred = pred.cpu().numpy()\r\n",
    "    gt = gt.cpu().numpy()\r\n",
    "    for i in range(8):\r\n",
    "        single_gt = gt==i\r\n",
    "        single_pred = pred==i\r\n",
    "        temp_tp = np.sum(single_gt * single_pred)\r\n",
    "        temp_ta = np.sum(single_pred) + np.sum(single_gt) - temp_tp\r\n",
    "        result[\"TP\"][i] += temp_tp\r\n",
    "        result[\"TA\"][i] += temp_ta\r\n",
    "    return result\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\r\n",
    "    # model config\r\n",
    "    OUTPUT_STRIDE = 16\r\n",
    "    ASPP_OUTDIM = 256\r\n",
    "    SHORTCUT_DIM = 48\r\n",
    "    SHORTCUT_KERNEL = 1\r\n",
    "    NUM_CLASSES = 8\r\n",
    "\r\n",
    "    # train config\r\n",
    "    EPOCHS = 10\r\n",
    "    WEIGHT_DECAY = 1.0e-4\r\n",
    "    LOG_SAVE_PATH = \"logs\"\r\n",
    "    MODEL_SAVE_PATH = \"modelweights\"\r\n",
    "    BASE_LR = 1e-3\r\n",
    "    LOSS_WEIGHT = 0.5\r\n",
    "    CLR_BASE = 1e-4\r\n",
    "    CLR_MAX = 1e-3\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\r\n",
    "import torch\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision import transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "\r\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\r\n",
    "\r\n",
    "device_list = [0]\r\n",
    "train_net = 'deeplabv3p' # 'unet'\r\n",
    "# nets['deeplabv3p']:DeeplabVePlus\r\n",
    "nets = {'deeplabv3p': DeeplabV3Plus, 'unet': ResNetUNet}\r\n",
    "\r\n",
    "def loss_func(predict, target, nbclasses, epoch):\r\n",
    "    ''' can modify or add losses '''\r\n",
    "    ce_loss = MySoftmaxCrossEntropyLoss(nbclasses=nbclasses)(predict, target)\r\n",
    "    return ce_loss\r\n",
    "\r\n",
    "\r\n",
    "def train_epoch(net, epoch, dataLoader, optimizer, trainF, config):\r\n",
    "    net.train()\r\n",
    "    total_mask_loss, mask_loss = 0.0, 0.0\r\n",
    "    dataprocess = tqdm(dataLoader)\r\n",
    "    for batch_item in dataprocess:\r\n",
    "        image, mask = batch_item['image'], batch_item['mask']\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            image, mask = image.cuda(device=device_list[0]), mask.cuda(device=device_list[0])\r\n",
    "        optimizer.zero_grad()\r\n",
    "        # cbrp-cbrp-\r\n",
    "        out = net(image)\r\n",
    "        if epoch < 3:\r\n",
    "            mask_loss = MySoftmaxCrossEntropyLoss(nbclasses=config.NUM_CLASSES)(out, mask) \r\n",
    "        else:\r\n",
    "            mask_loss = MySoftmaxCrossEntropyLoss(nbclasses=config.NUM_CLASSES)(out, mask) * config.LOSS_WEIGHT + \\\r\n",
    "            DiceLoss(nbclasses=config.NUM_CLASSES)(out, mask) * (1 - config.LOSS_WEIGHT)\r\n",
    "        total_mask_loss += mask_loss.item()\r\n",
    "        mask_loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        # scheduler.step()\r\n",
    "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\r\n",
    "        dataprocess.set_postfix_str(\"mask_loss:{:.4f}\".format(mask_loss.item()))\r\n",
    "    trainF.write(\"Epoch:{}, mask loss is {:.4f} \\n\".format(epoch, total_mask_loss / len(dataLoader)))\r\n",
    "    trainF.flush()\r\n",
    "\r\n",
    "\r\n",
    "def test(net, epoch, dataLoader, testF, config):\r\n",
    "    net.eval()\r\n",
    "    total_mask_loss = 0.0\r\n",
    "    dataprocess = tqdm(dataLoader)\r\n",
    "    result = {\"TP\": {i:0 for i in range(8)}, \"TA\":{i:0 for i in range(8)}}\r\n",
    "    for batch_item in dataprocess:\r\n",
    "        image, mask = batch_item['image'], batch_item['mask']\r\n",
    "        if torch.cuda.is_available():\r\n",
    "            image, mask = image.cuda(device=device_list[0]), mask.cuda(device=device_list[0])\r\n",
    "        out = net(image)\r\n",
    "        mask_loss = DiceLoss(nbclasses=config.NUM_CLASSES)(out, mask)\r\n",
    "        total_mask_loss += mask_loss.detach().item()\r\n",
    "        pred = torch.argmax(F.softmax(out, dim=1), dim=1)\r\n",
    "        result = compute_iou(pred, mask, result)\r\n",
    "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\r\n",
    "        dataprocess.set_postfix_str(\"mask_loss:{:.4f}\".format(mask_loss))\r\n",
    "    testF.write(\"Epoch:{} \\n\".format(epoch))\r\n",
    "    miou = 0\r\n",
    "    for i in range(8):\r\n",
    "        iou_i = result[\"TP\"][i]/result[\"TA\"][i]\r\n",
    "        result_string = \"{}: {:.4f} \\n\".format(i, iou_i)\r\n",
    "        print(result_string)\r\n",
    "        testF.write(result_string)\r\n",
    "        miou += iou_i\r\n",
    "    miou /= 8\r\n",
    "    miou_string = \"{}: {:.4f} \\n\".format('miou', miou)\r\n",
    "    print(miou_string)\r\n",
    "    testF.write(miou_string)\r\n",
    "    testF.write(\"Epoch:{}, mask loss is {:.4f} \\n\".format(epoch, total_mask_loss / len(dataLoader)))\r\n",
    "    testF.flush()\r\n",
    "    return miou\r\n",
    "\r\n",
    "def adjust_lr(optimizer, epoch):\r\n",
    "    if epoch == 4:\r\n",
    "        lr = 3e-4\r\n",
    "    elif epoch == 6:\r\n",
    "        lr = 5e-5\r\n",
    "    elif epoch == 8:\r\n",
    "        lr = 1e-5\r\n",
    "    else:\r\n",
    "        return\r\n",
    "    for param_group in optimizer.param_groups:\r\n",
    "        param_group['lr'] = lr\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def main():\r\n",
    "    lane_config = Config()\r\n",
    "    if os.path.exists(lane_config.LOG_SAVE_PATH):\r\n",
    "        shutil.rmtree(lane_config.LOG_SAVE_PATH)\r\n",
    "    os.makedirs(lane_config.LOG_SAVE_PATH, exist_ok=True)\r\n",
    "    trainF = open(os.path.join(lane_config.LOG_SAVE_PATH, \"train_log.csv\"), 'w')\r\n",
    "    testF = open(os.path.join(lane_config.LOG_SAVE_PATH, \"val_log.csv\"), 'w')\r\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\r\n",
    "    # ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm)\r\n",
    "    # 出现这个错误的情况是，在服务器上的docker中运行训练代码时，batch size设置得过大，shared memory不够（因为docker限制了shm）.解决方法是，将Dataloader的num_workers设置为1.\r\n",
    "\r\n",
    "    train_dataset = LaneDataset(\"data_list/train.csv\", transform=transforms.Compose([ImageAug(), DeformAug(),\r\n",
    "                                                                              ScaleAug(), CutOut(32, 0.5), ToTensor()]))\r\n",
    "    # train_dataset = LaneDatasetLMDB(\"data_list/train.csv\", \"lmdb\", transform=transforms.Compose([ImageAug(), DeformAug(), ScaleAug(), CutOut(32, 0.5), ToTensor()]))\r\n",
    "    train_data_batch = DataLoader(train_dataset, batch_size=8*len(device_list), shuffle=True, drop_last=True, **kwargs)\r\n",
    "    val_dataset = LaneDataset(\"data_list/val.csv\", transform=transforms.Compose([ToTensor()]))\r\n",
    "    # val_dataset = LaneDatasetLMDB(\"data_list/val.csv\", 'lmdb', transform=transforms.Compose([ToTensor()]))\r\n",
    "    val_data_batch = DataLoader(val_dataset, batch_size=4*len(device_list), shuffle=False, drop_last=False, **kwargs)\r\n",
    "    net = nets[train_net](lane_config)\r\n",
    "    if torch.cuda.is_available():\r\n",
    "        net = net.cuda(device=device_list[0])\r\n",
    "        net = torch.nn.DataParallel(net, device_ids=device_list)\r\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=lane_config.BASE_LR,\r\n",
    "    #                             momentum=0.9, weight_decay=lane_config.WEIGHT_DECAY)\r\n",
    "    optimizer = torch.optim.Adam([{'params' : net.parameters() , 'initial_lr' : lane_config.BASE_LR}], lr=lane_config.BASE_LR, weight_decay=lane_config.WEIGHT_DECAY)\r\n",
    "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, lane_config.CLR_BASE, lane_config.CLR_MAX, step_size_up=1000, step_size_down=1000, \\\r\n",
    "    # mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=False, last_epoch=2)\r\n",
    "    max_miou = 0\r\n",
    "    for epoch in range(lane_config.EPOCHS):\r\n",
    "        adjust_lr(optimizer, epoch)\r\n",
    "        train_epoch(net, epoch, train_data_batch, optimizer, trainF, lane_config)\r\n",
    "        current_miou = test(net, epoch, val_data_batch, testF, lane_config)\r\n",
    "        if current_miou > max_miou:\r\n",
    "            max_miou = current_miou\r\n",
    "            if os.path.exists(lane_config.MODEL_SAVE_PATH):\r\n",
    "                shutil.rmtree(lane_config.MODEL_SAVE_PATH)\r\n",
    "            os.makedirs(lane_config.MODEL_SAVE_PATH, exist_ok=True)\r\n",
    "            torch.save({'state_dict': net.state_dict()}, os.path.join(os.getcwd(), lane_config.MODEL_SAVE_PATH, \"laneNet{}.pth.tar\".format(epoch)))\r\n",
    "    trainF.close()\r\n",
    "    testF.close()\r\n",
    "    # torch.save({'state_dict': net.state_dict()}, os.path.join(os.getcwd(), lane_config.SAVE_PATH, \"finalNet.pth.tar\"))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/aistudio/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
